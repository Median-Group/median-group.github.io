<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Median Group</title><link href="/" rel="alternate"></link><link href="None/feed/atom.xml" rel="self"></link><id>/</id><updated>2019-03-24T00:00:00-07:00</updated><entry><title>Feasibility of Training an AGI using Deep Reinforcement Learning: A Very Rough Estimate</title><link href="/rough_agi.html" rel="alternate"></link><published>2019-03-24T00:00:00-07:00</published><updated>2019-03-24T00:00:00-07:00</updated><author><name>Baeo Maltinsky</name></author><id>tag:None,2019-03-24:/rough_agi.html</id><summary type="html">&lt;p&gt;Exploring a suggested scenario for near-term &lt;span class="caps"&gt;AGI&lt;/span&gt;&lt;/p&gt;</summary><content type="html">&lt;p&gt;Several months, we were presented with a scenario for how artificial general intelligence (&lt;span class="caps"&gt;AGI&lt;/span&gt;) may be achieved in the near future. We found the approach surprising, so we attempted to produce a rough model to investigate its feasibility. The document presents the model and its&amp;nbsp;conclusions.&lt;/p&gt;
&lt;p&gt;The usual cliches about the folly of trying to predict the future go without saying and this shouldn&amp;#8217;t be treated as a rigorous estimate, but hopefully it can give a loose, rough sense of some of the relevant quantities involved. The notebook and the data used for it can be found in the Median Group numbers GitHub repo if the reader is interested in using different quantities or changing the structure of the model. If the reader is interested in a more general approach based on the rate of theoretical progress, see our &lt;a href="http://mediangroup.org/insights"&gt;Insights model&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;a href="docs/Feasibility of Training an AGI using Deep Reinforcement Learning, A Very Rough Estimate.pdf"&gt;Download &lt;span class="caps"&gt;PDF&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;</content></entry><entry><title>The Brain and Computation</title><link href="/brain1.html" rel="alternate"></link><published>2018-11-24T00:00:00-08:00</published><updated>2018-11-24T00:00:00-08:00</updated><author><name>Baeo Maltinsky</name></author><id>tag:None,2018-11-24:/brain1.html</id><summary type="html">&lt;h1 id="measuring-computation"&gt;Measuring&amp;nbsp;Computation&lt;/h1&gt;
&lt;p&gt;The computational performance of microprocessors can be quantified by measuring the number of floating-point arithmetic operations the processor can perform per second (&lt;span class="caps"&gt;FLOPS&lt;/span&gt;). This number is very useful for comparing different hardware being used for numerically intensive applications like scientific computing or mining &lt;a href="https://en.wikipedia.org/wiki/Cryptocurrency"&gt;fake internet points&lt;/a&gt;, but some …&lt;/p&gt;</summary><content type="html">&lt;h1 id="measuring-computation"&gt;Measuring&amp;nbsp;Computation&lt;/h1&gt;
&lt;p&gt;The computational performance of microprocessors can be quantified by measuring the number of floating-point arithmetic operations the processor can perform per second (&lt;span class="caps"&gt;FLOPS&lt;/span&gt;). This number is very useful for comparing different hardware being used for numerically intensive applications like scientific computing or mining &lt;a href="https://en.wikipedia.org/wiki/Cryptocurrency"&gt;fake internet points&lt;/a&gt;, but some have attempted to quantify the computation done by the human brain in these terms to reason about how difficult it would be to run a human-level intelligence on modern computing&amp;nbsp;hardware.&lt;/p&gt;
&lt;p&gt;This post will discuss a few of the issues associated with measuring the computational performance of the brain with &lt;span class="caps"&gt;FLOPS&lt;/span&gt;, and a follow-up post will consider specific&amp;nbsp;estimates.&lt;/p&gt;
&lt;h1 id="does-it-make-sense-to-think-about-the-computational-capacity-of-the-brain-in-terms-of-flops"&gt;Does it make sense to think about the computational capacity of the brain in terms of &lt;span class="caps"&gt;FLOPS&lt;/span&gt;?&lt;/h1&gt;
&lt;p&gt;There is a line of thinking that goes something&amp;nbsp;like:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Neurons generate action potentials. Action potentials are stereotyped signals, so the computation that happens in the brain is essentially digital, so it makes sense to compare brains to digital computers, and synaptic operations are kind of like arithmetic&amp;nbsp;operations.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;This may or may not be a good enough approximation, but it&amp;#8217;s definitely a lossy&amp;nbsp;approximation.&lt;/p&gt;
&lt;h2 id="brains-probably-arent-bottlenecked-on-arithmetic"&gt;Brains probably aren&amp;#8217;t bottlenecked on&amp;nbsp;arithmetic&lt;/h2&gt;
&lt;p&gt;A common objection to measuring the performance of the brain in &lt;span class="caps"&gt;FLOPS&lt;/span&gt; is that computation in the brain isn&amp;#8217;t bottlenecked by arithmetic capacity, but rather by information flow, so the capacity of the brain should be measured in &lt;em&gt;traversed edges per second&lt;/em&gt; (&lt;span class="caps"&gt;TEPS&lt;/span&gt;) rather than &lt;span class="caps"&gt;FLOPS&lt;/span&gt;. Synaptic connections between neurons tend to be sparse and axons tend to be long, which seems to suggest a lot of neural tissue is dedicated to pushing signals around rather than performing arithmetic on them&lt;sup id="fnref-1"&gt;&lt;a class="footnote-ref" href="#fn-1"&gt;1&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;h2 id="brains-are-asynchronous"&gt;Brains are&amp;nbsp;asynchronous&lt;/h2&gt;
&lt;p&gt;Microprocessors are clocked circuits. When a computation unfolds on a microprocessor, it proceeds in discrete, well-delineated steps with one occurring each processor cycle. This method of computation is fundamentally&amp;nbsp;synchronous.&lt;/p&gt;
&lt;p&gt;Brains don&amp;#8217;t have a clock: neurons fire when they fire, which usually isn&amp;#8217;t very often (one to ten times a second), but is sometimes much faster (up to around 1000 Hz)&lt;sup id="fnref-2"&gt;&lt;a class="footnote-ref" href="#fn-2"&gt;2&lt;/a&gt;&lt;/sup&gt;. And the phase of the neural spike trains also seem to be important&lt;sup id="fnref-3"&gt;&lt;a class="footnote-ref" href="#fn-3"&gt;3&lt;/a&gt;&lt;/sup&gt;, which further complicates the&amp;nbsp;comparison.&lt;/p&gt;
&lt;h2 id="non-spiking-neurons"&gt;Non-spiking&amp;nbsp;neurons&lt;/h2&gt;
&lt;p&gt;Many neurons &lt;a href="https://en.wikipedia.org/wiki/Non-spiking_neuron"&gt;don&amp;#8217;t even spike&lt;/a&gt;, having graded, non-stereotyped potentials. The best-studied are the photo-receptive neurons in the retina, but they occur throughout the brain and it&amp;#8217;s unclear how to integrate them into the larger computational picture of the&amp;nbsp;brain.&lt;/p&gt;
&lt;h1 id="conclusion"&gt;Conclusion&lt;/h1&gt;
&lt;p&gt;This post was not meant to be comprehensive, and is merely meant to highlight the strangeness and limitations of thinking of the limits of neural computation in terms of &lt;span class="caps"&gt;FLOPS&lt;/span&gt;.&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id="fn-1"&gt;
&lt;p&gt;Limitations in the ability of evolution to modify the basic vertebrate developmental plan lead can lead to bizarre inefficiencies, like the optic nerve needing to carry signals &lt;a href="https://en.wikipedia.org/wiki/Lateral_geniculate_nucleus"&gt;from the retina to the back of the head&lt;/a&gt; before being processed in the visual cortex, or in the case of giraffes the laryngeal nerve needing to take a &lt;a href="https://en.wikipedia.org/wiki/Recurrent_laryngeal_nerve#Evidence_of_evolution"&gt;&amp;gt;4 meter detour&lt;/a&gt;.&amp;#160;&lt;a class="footnote-backref" href="#fnref-1" title="Jump back to footnote 1 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn-2"&gt;
&lt;p&gt;See &lt;a href="https://en.wikipedia.org/wiki/Neural_coding#Sparse_coding"&gt;sparse coding&lt;/a&gt;.&amp;#160;&lt;a class="footnote-backref" href="#fnref-2" title="Jump back to footnote 2 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn-3"&gt;
&lt;p&gt;See &lt;a href="https://en.wikipedia.org/wiki/Neural_coding#Phase-of-firing_code"&gt;phase coding&lt;/a&gt;.&amp;#160;&lt;a class="footnote-backref" href="#fnref-3" title="Jump back to footnote 3 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</content></entry><entry><title>How rapidly are GPUs improving in price performance?</title><link href="/gpu.html" rel="alternate"></link><published>2018-11-13T12:00:00-08:00</published><updated>2018-11-13T12:00:00-08:00</updated><author><name>Baeo Maltinsky</name></author><id>tag:None,2018-11-13:/gpu.html</id><summary type="html">&lt;p&gt;A Brief Look at Trends in &lt;span class="caps"&gt;GPU&lt;/span&gt;&amp;nbsp;price-performance&lt;/p&gt;</summary><content type="html">&lt;noscript&gt;
  &lt;p&gt;
    Note: Equations will not render properly with javascript&amp;nbsp;disabled.
  &lt;/p&gt;
&lt;/noscript&gt;

&lt;h1 id="introduction"&gt;Introduction&lt;/h1&gt;
&lt;p&gt;Many of the impressive results in deep learning in recent years have been achieved through massive investment in hardware needed for training, with projects like AlphaGo Zero using &lt;a href="https://www.nature.com/news/self-taught-ai-is-best-yet-at-strategy-game-go-1.22858#/ref-link-2"&gt;$25 million&lt;/a&gt; worth of computer hardware. Given this, improvements in price-performance of hardware used for deep learning will play an important role in determining the scale of projects in the coming&amp;nbsp;years.&lt;/p&gt;
&lt;p&gt;While machine learning &lt;a href="https://en.wikipedia.org/wiki/Application-specific_integrated_circuit"&gt;ASICs&lt;/a&gt; like TPUs are likely the future, the recent deep learning boom was powered by GPUs&lt;sup id="fnref-1"&gt;&lt;a class="footnote-ref" href="#fn-1"&gt;1&lt;/a&gt;&lt;/sup&gt;. The architectures of TPUs and GPUs differ in important ways, but much of the design and fabrication process is similar and both are largely focused on efficient, parallelized arithmetic&lt;sup id="fnref-2"&gt;&lt;a class="footnote-ref" href="#fn-2"&gt;2&lt;/a&gt;&lt;/sup&gt;, so trends observed in GPUs can inform us about what to expect from&amp;nbsp;TPUs.&lt;/p&gt;
&lt;p&gt;Commonly mentioned figures for the price-performance generalization of Moore&amp;#8217;s Law suggest that price-performance doubles roughly every two years, but this figure warranted further&amp;nbsp;investigation. &lt;/p&gt;
&lt;h1 id="data"&gt;Data&lt;/h1&gt;
&lt;p&gt;We constructed a &lt;a href="/data/gpu.csv"&gt;data set&lt;/a&gt; containing the model name, launch date, single precision performance in &lt;span class="caps"&gt;GFLOPS&lt;/span&gt;, and release price in non-inflation adjusted &lt;span class="caps"&gt;US&lt;/span&gt; dollars for 223 Nvidia and &lt;span class="caps"&gt;AMD&lt;/span&gt; GPUs (scraped from Wikipedia)&lt;sup id="fnref-3"&gt;&lt;a class="footnote-ref" href="#fn-3"&gt;3&lt;/a&gt;&lt;/sup&gt;. The data set covered almost two decades, so prices were adjusted to 2018 &lt;span class="caps"&gt;US&lt;/span&gt; dollars using the &lt;a href="https://fred.stlouisfed.org/series/CPIAUCNS"&gt;Consumer Price Index&lt;/a&gt;.&lt;/p&gt;
&lt;h1 id="analysis"&gt;Analysis&lt;/h1&gt;
&lt;p&gt;Fitting an exponential to the data-set yielded the&amp;nbsp;curve:
&lt;/p&gt;
&lt;div class="math"&gt;\begin{equation}
    f(t) \approx 14.2 e^{0.2 t}
\end{equation}&lt;/div&gt;
&lt;p&gt;&lt;img alt="GPU Price-Performance" src="/images/gpu_full.png"&gt;&lt;/p&gt;
&lt;p&gt;This implies a doubling time of &lt;span class="math"&gt;\(\sim 3.5\)&lt;/span&gt; years. It should be noted that this is somewhat misleading because the price-performance curve isn&amp;#8217;t a clean exponential. Inspecting a log-plot suggests that price-performance has been in a distinctly slower growth regime since around&amp;nbsp;2012.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Log-plot of GPU price-performance" src="/images/gpu_log.png"&gt;&lt;/p&gt;
&lt;p&gt;Fitting to data from 2012 or later yields the&amp;nbsp;curve:
&lt;/p&gt;
&lt;div class="math"&gt;\begin{equation}
    f(t) \approx 15.2 e^{0.176 t},
\end{equation}&lt;/div&gt;
&lt;p&gt;
corresponding to a doubling time of ~3.9&amp;nbsp;years.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Log-plot of GPU price-performance" src="/images/gpu_log.png"&gt;&lt;/p&gt;
&lt;h1 id="external-discussion"&gt;External&amp;nbsp;Discussion&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.lesswrong.com/posts/iGznDsxfB564Lobam/how-rapidly-are-gpus-improving-in-price-performance"&gt;Comments on LessWrong&lt;/a&gt; about this&amp;nbsp;article&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="footnote"&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id="fn-1"&gt;
&lt;p&gt;GPUs are still more cost effective than TPUs, but have lower serial computation speed.&amp;#160;&lt;a class="footnote-backref" href="#fnref-1" title="Jump back to footnote 1 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn-2"&gt;
&lt;p&gt;This is not nearly as true as with CPUs which have managed to extract performance improvements from &lt;a href="http://www.lighterra.com/papers/modernmicroprocessors/"&gt;increasingly arcane changes to control circuitry&lt;/a&gt;.&amp;#160;&lt;a class="footnote-backref" href="#fnref-2" title="Jump back to footnote 2 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn-3"&gt;
&lt;p&gt;&lt;span class="caps"&gt;AI&lt;/span&gt; Impacts has a &lt;a href="https://docs.google.com/spreadsheets/d/1yqX2cENwkOxC26wV_sBOvV0NxHzzfmL6tU7StzrFXRc/edit#gid=51141192"&gt;similar data set&lt;/a&gt;.&amp;#160;&lt;a class="footnote-backref" href="#fnref-3" title="Jump back to footnote 3 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</content></entry><entry><title>AGNI</title><link href="/agni.html" rel="alternate"></link><published>2018-10-03T16:54:36-07:00</published><updated>2018-10-03T16:54:36-07:00</updated><author><name>Baeo Maltinsky</name></author><id>tag:None,2018-10-03:/agni.html</id><summary type="html">&lt;p&gt;A proposal for improved forest fire&amp;nbsp;forecasting&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;a href="docs/agni.pdf"&gt;Download &lt;span class="caps"&gt;PDF&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;</content></entry><entry><title>Insight-based AI timelines model</title><link href="/insights.html" rel="alternate"></link><published>2018-06-12T00:00:00-07:00</published><updated>2018-06-12T00:00:00-07:00</updated><author><name>Baeo Maltinsky</name></author><id>tag:None,2018-06-12:/insights.html</id><summary type="html">
   &lt;noscript&gt;
     &lt;p&gt;
       Note: the demos on this page will not work with javascript&amp;nbsp;disabled. 
     &lt;/p&gt;
   &lt;/noscript&gt;
    &lt;h1&gt; Insight-based &lt;span class="caps"&gt;AI&lt;/span&gt; timeline&amp;nbsp;model&lt;/h1&gt;
    &lt;p&gt;
    For various &amp;#8220;percentages of the way&amp;#8221; done &lt;span class="caps"&gt;AI&lt;/span&gt; research could be, in terms of percentage of the necessary insights discovered, what is the probability that &lt;span class="caps"&gt;AI&lt;/span&gt; research is not yet that percentage&amp;nbsp;done?
    &lt;/p&gt;
    &lt;div style="position:relative"&gt;
      &lt;div style="display:flex;flex-direction:row"&gt;
        &lt;div style="position:relative;min-width:80px"&gt;
          &lt;p style="position:absolute;top:-8px;right:10px;margin:0px"&gt;100 …&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</summary><content type="html">
   &lt;noscript&gt;
     &lt;p&gt;
       Note: the demos on this page will not work with javascript&amp;nbsp;disabled. 
     &lt;/p&gt;
   &lt;/noscript&gt;
    &lt;h1&gt; Insight-based &lt;span class="caps"&gt;AI&lt;/span&gt; timeline&amp;nbsp;model&lt;/h1&gt;
    &lt;p&gt;
    For various &amp;#8220;percentages of the way&amp;#8221; done &lt;span class="caps"&gt;AI&lt;/span&gt; research could be, in terms of percentage of the necessary insights discovered, what is the probability that &lt;span class="caps"&gt;AI&lt;/span&gt; research is not yet that percentage&amp;nbsp;done?
    &lt;/p&gt;
    &lt;div style="position:relative"&gt;
      &lt;div style="display:flex;flex-direction:row"&gt;
        &lt;div style="position:relative;min-width:80px"&gt;
          &lt;p style="position:absolute;top:-8px;right:10px;margin:0px"&gt;100%&lt;/p&gt;
          &lt;p style="position:absolute;top:60px;margin:0px;writing-mode: sideways-lr;"&gt;P(no more than this much of the way&amp;nbsp;done)&lt;/p&gt;
          &lt;p style="position:absolute;top:492px;right:10px;margin:0px"&gt;0%&lt;/p&gt;
        &lt;/div&gt;
        &lt;div&gt;
          &lt;canvas id="progress_distr" width="500" height="500" style="border: 1px solid #545454; box-shadow: 0px 0px 2px 1px;"&gt;&lt;/canvas&gt;
        &lt;/div&gt;
      &lt;/div&gt;
      &lt;div style="position:absolute;left:80px;display:flex;flex-direction:row"&gt;
        &lt;p&gt;0%&lt;/p&gt;
        &lt;div style="float:right;position:absolute;left:460px"&gt;
          &lt;p&gt;100%&lt;/p&gt;
        &lt;/div&gt;
      &lt;/div&gt;
      &lt;br /&gt;
      &lt;div style="position:relative;left:120px;width: fit-content"&gt;
        &lt;p&gt;Proportion of required insights that have been&amp;nbsp;discovered&lt;/p&gt;
      &lt;/div&gt;
    &lt;/div&gt;
    &lt;br /&gt;
    &lt;button id="clear_button"&gt;Clear&lt;/button&gt;

    &lt;h2&gt;Pre-set&amp;nbsp;priors&lt;/h2&gt;

    &lt;p&gt;Instead of drawing a cumulative distribution function, you can instead use a pre-set prior.  These priors are based on the &lt;a href="https://en.wikipedia.org/wiki/Pareto_distribution"&gt;Pareto distribution&lt;/a&gt;.  To make choice of the parameter more intuitive, we parameterize the distribution in terms of a probability &lt;i&gt;q&lt;/i&gt;, equal to the probability that a doubling in number of insights (starting from the minimum number of insights) would result in a sufficient set of&amp;nbsp;insights.  &lt;/p&gt;

    &lt;p&gt;Minimum plausible number of insights required: &lt;input type="text" value="10" id="min_insights" /&gt;&lt;/p&gt;
    &lt;p&gt;&lt;i&gt;q&lt;/i&gt;: &lt;input type="number" value="0.2" id="pareto_q"&gt; &lt;button id="pareto_button"&gt;Pareto distribution&lt;/button&gt;&lt;/p&gt;
    &lt;p&gt;&lt;button id="uniform_pareto_button"&gt;Pareto distribution, &lt;i&gt;q&lt;/i&gt; ~ Uniform(0,1)&lt;/button&gt;
    &lt;p&gt;&lt;i&gt;&amp;alpha;&lt;/i&gt;: &lt;input type="number" value="1" id="alpha"&gt;
    &lt;i&gt;&amp;beta;&lt;/i&gt;: &lt;input type="number" value="1" id="beta"&gt;
    &lt;button id="beta_pareto_button"&gt;Pareto distribution, &lt;i&gt;q&lt;/i&gt; ~ Beta(&amp;alpha;, &amp;beta;)&lt;/button&gt;&lt;/p&gt;




    &lt;h2&gt;Resulting&amp;nbsp;timeline&lt;/h2&gt;

    &lt;p&gt;Assuming a linear increase in number of required insights over time, the following cumulative distribution function for time when all required insights are discovered is implied by these&amp;nbsp;beliefs.&lt;/p&gt;
    &lt;div id="timeline_placeholder" style="width:800px;height:400px"&gt;&lt;/div&gt;
    Adjust the maximum year displayed: &lt;input type="range" min="2050" max="3000" value="2200" id="last_year" style="width:300px" /&gt;

    &lt;h1&gt; Derivation &lt;/h1&gt;

    &lt;p&gt; How was this data generated?  Jessica Taylor, Jack Gallagher, and Baeo Maltinsky spent a few hours generating a list of &lt;span class="caps"&gt;AI&lt;/span&gt; insights that seemed around the same order of significance or more significant than the insight of &lt;span class="caps"&gt;LSTM&lt;/span&gt; (specifically, the insight of inventing &lt;span class="caps"&gt;LSTM&lt;/span&gt; given that RNNs were already invented).  The following is a plot of number of &lt;span class="caps"&gt;AI&lt;/span&gt; insights in our list over time since&amp;nbsp;1850.&lt;/p&gt;

    &lt;div id="insights_placeholder" style="width:800px;height:400px"&gt;&lt;/div&gt;

    &lt;p&gt;The model assumes that insights increase linearly over time.  The increase has been roughly linear since 1945, but this could change due to low hanging fruit, expanding research avenues, changes in the number and effectiveness of research institutions, and so on.  The model does not distinguish between insights in our list (which we selected according to some subjective estimation of importance) and specifically &lt;i&gt;required&lt;/i&gt; insights; however, if the percentage of insights that are actually required stays somewhat constant over time, this does not significantly affect the&amp;nbsp;timeline.&lt;/p&gt;

    &lt;p&gt;The list of insights and their years can be found in &lt;a href="../docs/AI_insights.pdf"&gt;this document&lt;/a&gt;.&lt;/p&gt;


&lt;script src="../scripts/jquery.js" type="text/javascript"&gt;&lt;/script&gt;
    &lt;script src="../scripts/jstat.js" type="text/javascript"&gt;&lt;/script&gt;
    &lt;script src="../scripts/flot/jquery.flot.js" type="text/javascript"&gt;&lt;/script&gt;
    &lt;script src="../scripts/insights.js" type="text/javascript"&gt;&lt;/script&gt;


  </content></entry></feed>